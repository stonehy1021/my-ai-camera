import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration
import cv2
import mediapipe as mp
import av
import numpy as np
import time
import queue  # ë°ì´í„° ì „ì†¡ìš© í

# ---------------- 1. ê¸°ë³¸ ì„¤ì • ----------------
st.set_page_config(page_title="mzêµ¬ë„ ì´¬ì˜ê¸° (ì €ì¥ê°€ëŠ¥)", layout="centered")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì°ì€ ì‚¬ì§„ ì €ì¥ìš©)
if "snapshot" not in st.session_state:
    st.session_state.snapshot = None

st.title("ğŸ“¸ mzêµ¬ë„ ìë™ ì´¬ì˜ê¸° ")
st.info("ì›í•˜ëŠ” ê°ë„ë¥¼ ì„¤ì •í•˜ê³  ì´¬ì˜í•˜ì„¸ìš”!")

# ---------------- 2. ì‚¬ì´ë“œë°” ì„¤ì • ----------------
st.sidebar.header("âš™ï¸ ì„¤ì •")
# ëª¨ë°”ì¼ í™”ê° ê³ ë ¤í•œ ë²”ìœ„ (0.02 ~ 0.15)
min_val = st.sidebar.slider("ìµœì†Œ ê°ë„", 0.0, 0.3, 0.13, 0.01)
max_val = st.sidebar.slider("ìµœëŒ€ ê°ë„", 0.0, 0.3, 0.25, 0.01)

# ---------------- 3. Mediapipe ì´ˆê¸°í™” ----------------
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(
    max_num_faces=1,
    refine_landmarks=True,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)

# ---------------- 4. ì˜ìƒ ì²˜ë¦¬ í´ë˜ìŠ¤ ----------------
class VideoProcessor(VideoProcessorBase):
    def __init__(self):
        self.enter_time = None
        self.capture_triggered = False
        self.last_capture_time = 0
        self.flash_frame = 0
        # ë©”ì¸ ìŠ¤ë ˆë“œë¡œ ì‚¬ì§„ì„ ë³´ë‚´ê¸° ìœ„í•œ ìš°ì²´í†µ(Queue)
        self.result_queue = queue.Queue()

    def recv(self, frame):
        # ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
        img = frame.to_ndarray(format="bgr24")
        img = cv2.flip(img, 1) # ê±°ìš¸ ëª¨ë“œ
        h, w, _ = img.shape
        
        # ì–¼êµ´ ë¶„ì„
        rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = face_mesh.process(rgb_img)
        
        current_z = 0.0
        in_range = False
        border_color = (0, 0, 255) # ë¹¨ê°•
        status_msg = "Adjust Angle"
        
        # í”Œë˜ì‹œ íš¨ê³¼
        if self.flash_frame > 0:
            self.flash_frame -= 1
            white = np.full((h, w, 3), 255, dtype=np.uint8)
            img = cv2.addWeighted(img, 0.5, white, 0.5, 0)

        if results.multi_face_landmarks:
            landmarks = results.multi_face_landmarks[0].landmark
            chin = landmarks[152].z
            forehead = landmarks[10].z
            current_z = (chin - forehead)
            
            # ë²”ìœ„ ì²´í¬ (0.02 ~ 0.15)
            # (í´ë˜ìŠ¤ ë‚´ë¶€ë¼ ìŠ¬ë¼ì´ë” ê°’ì„ ì§ì ‘ ë°›ê¸° ì–´ë ¤ì›Œ ëª¨ë°”ì¼ ìµœì ê°’ìœ¼ë¡œ ê³ ì •í•˜ê±°ë‚˜ ë„“ê²Œ ì¡ìŒ)
            if 0.02 <= current_z <= 0.20: 
                in_range = True
                border_color = (0, 255, 0) # ì´ˆë¡
                status_msg = "HOLD ON!"
            
            # ê·¸ë¦¬ê¸°
            cv2.rectangle(img, (0,0), (w,h), border_color, 20)
            cv2.putText(img, f"Z: {current_z:.4f}", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.5, border_color, 3)
            cv2.putText(img, status_msg, (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 3)
            
            # ìë™ ì´¬ì˜ ë¡œì§
            if in_range:
                if self.enter_time is None:
                    self.enter_time = time.time()
                
                elapsed = time.time() - self.enter_time
                countdown = 1.5 - elapsed
                
                if countdown > 0:
                    # ì¹´ìš´íŠ¸ë‹¤ìš´
                    cx, cy = w//2, h//2
                    cv2.putText(img, f"{countdown:.1f}", (cx-50, cy+20), cv2.FONT_HERSHEY_SIMPLEX, 4, (0, 255, 255), 5)
                else:
                    # â˜… ì´¬ì˜ ì‹œì  â˜…
                    if not self.capture_triggered:
                        if time.time() - self.last_capture_time > 3:
                            
                            # [ì¤‘ìš”] ì°íŒ ì‚¬ì§„ì„ í(ìš°ì²´í†µ)ì— ë„£ì–´ì„œ ë©”ì¸ í™”ë©´ìœ¼ë¡œ ë³´ëƒ„
                            # (OpenCV ì´ë¯¸ì§€ëŠ” BGRì´ë¯€ë¡œ RGB ë³€í™˜í•´ì„œ ë³´ëƒ„)
                            save_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                            self.result_queue.put(save_img)
                            
                            self.last_capture_time = time.time()
                            self.capture_triggered = True
                            self.flash_frame = 5
            else:
                self.enter_time = None
                self.capture_triggered = False
                
        return av.VideoFrame.from_ndarray(img, format="bgr24")

# ---------------- 5. WebRTC ì‹¤í–‰ ë° ë‹¤ìš´ë¡œë“œ UI ----------------

# ë§Œì•½ ì°ì–´ë‘” ì‚¬ì§„ì´ ìˆìœ¼ë©´ í™”ë©´ì— ë³´ì—¬ì£¼ê³  ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„±
if st.session_state.snapshot is not None:
    st.success("ğŸ“¸ ì¸ìƒìƒ· ê±´ì§!")
    col1, col2 = st.columns(2)
    with col1:
        st.image(st.session_state.snapshot, caption="ë°©ê¸ˆ ì°ì€ ì‚¬ì§„", use_container_width=True)
    with col2:
        # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
        img_bgr = cv2.cvtColor(st.session_state.snapshot, cv2.COLOR_RGB2BGR)
        is_success, buffer = cv2.imencode(".jpg", img_bgr)
        
        if is_success:
            st.download_button(
                label="ğŸ“¥ ë‚´ í°ì— ì €ì¥í•˜ê¸°",
                data=buffer.tobytes(),
                file_name=f"Selfie_{int(time.time())}.jpg",
                mime="image/jpeg",
                type="primary"
            )
    
    if st.button("ğŸ”„ ë‹¤ì‹œ ì°ê¸°"):
        st.session_state.snapshot = None
        st.rerun()

# ì‚¬ì§„ì´ ì—†ì„ ë•Œë§Œ ì¹´ë©”ë¼ ë³´ì—¬ì£¼ê¸°
else:
    ctx = webrtc_streamer(
        key="mobile-camera-save",
        video_processor_factory=VideoProcessor,
        rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
        media_stream_constraints={"video": {"facingMode": "user"}, "audio": False},
    )

    # [í•µì‹¬] ì‹¤ì‹œê°„ìœ¼ë¡œ í í™•ì¸ (ì‚¬ì§„ì´ ì™”ë‚˜ ì•ˆ ì™”ë‚˜ ê°ì‹œ)
    if ctx.state.playing:
        status_ph = st.empty()
        while True:
            if ctx.video_processor:
                try:
                    # íì—ì„œ ì‚¬ì§„ êº¼ë‚´ê¸° (0.1ì´ˆ ëŒ€ê¸°)
                    result_img = ctx.video_processor.result_queue.get(timeout=0.1)
                    
                    # ì‚¬ì§„ì´ ë„ì°©í•˜ë©´ ì„¸ì…˜ì— ì €ì¥í•˜ê³  ìƒˆë¡œê³ ì¹¨!
                    if result_img is not None:
                        st.session_state.snapshot = result_img
                        st.rerun() # í™”ë©´ ê°±ì‹ í•´ì„œ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ë³´ì—¬ì¤Œ
                except queue.Empty:
                    # ì‚¬ì§„ ì—†ìœ¼ë©´ ê³„ì† ëŒ€ê¸°
                    pass
            time.sleep(0.1)


