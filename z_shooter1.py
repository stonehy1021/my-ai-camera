import streamlit as st
import cv2
import mediapipe as mp
import time
import os
import numpy as np

# ---------------- ê¸°ë³¸ ì„¤ì • ----------------
st.set_page_config(page_title="AI ìë™ ì´¬ì˜ê¸°", layout="wide")

# ìœˆë„ìš° ì•Œë¦¼ìŒ ì„¤ì • (ë§¥/ë¦¬ëˆ…ìŠ¤ ì—ëŸ¬ ë°©ì§€)
try:
    import winsound
except ImportError:
    winsound = None

# ì €ì¥ í´ë” ìƒì„±
SAVE_DIR = "captures"
if not os.path.exists(SAVE_DIR):
    os.makedirs(SAVE_DIR)

# ---------------- ì‚¬ì´ë“œë°” ì„¤ì • ----------------
st.sidebar.title("âš™ï¸ ì„¤ì • íŒ¨ë„")

# [ìš”ì²­í•˜ì‹  ê°ë„ ë²”ìœ„ ê³ ì •]
# ìŠ¬ë¼ì´ë”ë¡œ ì¡°ì ˆ ê°€ëŠ¥í•˜ì§€ë§Œ ê¸°ë³¸ê°’ì„ 0.23 ~ 0.28ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.
st.sidebar.subheader("1. ê°ë„ ë²”ìœ„ (Z-Diff)")
min_val = st.sidebar.slider("ìµœì†Œ ê°ë„", 0.10, 0.40, 0.23, 0.01)
max_val = st.sidebar.slider("ìµœëŒ€ ê°ë„", 0.10, 0.40, 0.28, 0.01)

st.sidebar.subheader("2. ì¹´ë©”ë¼ ì„ íƒ")
camera_id = st.sidebar.number_input("ì¹´ë©”ë¼ ë²ˆí˜¸ (0:ê¸°ë³¸, 1:ì™¸ë¶€)", 0, 5, 0)

# ---------------- Mediapipe ì´ˆê¸°í™” ----------------
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(
    max_num_faces=1,
    refine_landmarks=True,
    min_detection_confidence=0.5
)

# ---------------- ë©”ì¸ í™”ë©´ ----------------
st.title("ğŸ“¸ AI ìë™ ì´¬ì˜ê¸° (Local)")
st.markdown(f"""
### ğŸ¯ ëª©í‘œ ê°ë„: **{min_val} ~ {max_val}**
ì¹´ë©”ë¼ë¥¼ ì¼œê³  ê³ ê°œë¥¼ ì›€ì§ì—¬ **Z-Diff** ìˆ˜ì¹˜ë¥¼ ë§ì¶°ë³´ì„¸ìš”.  
ì´ˆë¡ìƒ‰ ìˆ«ìê°€ ëœ¨ë©´ **1.5ì´ˆ ë’¤ì— ìë™ìœ¼ë¡œ ì°í™ë‹ˆë‹¤!**
""")

# ì‹¤í–‰ ë²„íŠ¼
run = st.checkbox("ğŸš€ ì¹´ë©”ë¼ ì¼œê¸° (ì²´í¬í•˜ë©´ ì‹œì‘)", value=False)

# ì˜ìƒì´ ë‚˜ì˜¬ ê³µê°„
frame_window = st.image([])

# ---------------- ì‹¤í–‰ ë¡œì§ ----------------
if run:
    cap = cv2.VideoCapture(camera_id)

    if not cap.isOpened():
        st.error(f"ğŸš¨ ì¹´ë©”ë¼({camera_id}ë²ˆ)ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë²ˆí˜¸ë¥¼ 1ë¡œ ë°”ê¿”ë³´ê±°ë‚˜ ë‹¤ë¥¸ í”„ë¡œê·¸ë¨(Zoom ë“±)ì„ êº¼ì£¼ì„¸ìš”.")
    else:
        # ìƒíƒœ ë³€ìˆ˜
        last_capture_time = 0
        enter_time = None
        capture_triggered = False

        while run and cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                st.warning("í™”ë©´ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                break

            # 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            frame = cv2.flip(frame, 1)  # ê±°ìš¸ ëª¨ë“œ
            h, w, _ = frame.shape
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            # 2. ì–¼êµ´ ë¶„ì„
            results = face_mesh.process(rgb_frame)

            current_z = 0.0
            in_range = False
            status_text = "Out of Range"
            color = (0, 0, 255)  # ë¹¨ê°• (ë¶ˆì¼ì¹˜)

            if results.multi_face_landmarks:
                landmarks = results.multi_face_landmarks[0].landmark

                # Z-Diff ê³„ì‚°
                chin = landmarks[152].z
                forehead = landmarks[10].z
                current_z = chin - forehead

                # ë²”ìœ„ ì²´í¬
                if min_val <= current_z <= max_val:
                    in_range = True
                    status_text = "Target Locked!"
                    color = (0, 255, 0)  # ì´ˆë¡ (ì¼ì¹˜)

                # 3. í™”ë©´ì— ì •ë³´ í‘œì‹œ (í¬ê³  ì˜ ë³´ì´ê²Œ)
                # í˜„ì¬ ê°’
                cv2.putText(frame, f"Current: {current_z:.4f}", (30, 60),
                            cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)
                # ëª©í‘œ ë²”ìœ„
                cv2.putText(frame, f"Target: {min_val} ~ {max_val}", (30, 110),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)

                # 4. ìë™ ì´¬ì˜ ë¡œì§
                if in_range:
                    if enter_time is None:
                        enter_time = time.time()

                    # ê²½ê³¼ ì‹œê°„ ê³„ì‚°
                    elapsed = time.time() - enter_time

                    # 1.5ì´ˆ ì¹´ìš´íŠ¸ë‹¤ìš´ (ê¸°ì¡´ 3ì´ˆëŠ” ë„ˆë¬´ ê¸¸ì–´ì„œ ì¤„ì„)
                    countdown = 1.5 - elapsed

                    if countdown > 0:
                        # ì¹´ìš´íŠ¸ë‹¤ìš´ í‘œì‹œ
                        center_x, center_y = w // 2, h // 2
                        cv2.circle(frame, (center_x, center_y), 100, (0, 255, 255), 5)
                        cv2.putText(frame, f"{countdown:.1f}", (center_x - 40, center_y + 20),
                                    cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 255), 5)
                    else:
                        # [ì´¬ì˜ ì‹œì ]
                        if not capture_triggered:
                            # ì—°ì† ì´¬ì˜ ë°©ì§€ ì¿¨íƒ€ì„ (3ì´ˆ)
                            if time.time() - last_capture_time > 3:
                                # ì €ì¥
                                ts = int(time.time())
                                filename = f"{SAVE_DIR}/AutoShot_{ts}.jpg"
                                cv2.imwrite(filename, cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR))

                                # íš¨ê³¼ (ì†Œë¦¬ + í™”ë©´ ë²ˆì©)
                                if winsound: winsound.Beep(1000, 150)
                                cv2.rectangle(frame, (0, 0), (w, h), (255, 255, 255), -1)  # ì „ì²´ í°ìƒ‰ í™”ë©´(í”Œë˜ì‹œ)

                                st.toast(f"ğŸ“¸ ì°°ì¹µ! ì €ì¥ë¨: {filename}")
                                last_capture_time = time.time()
                                capture_triggered = True
                else:
                    # ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ íƒ€ì´ë¨¸ ë¦¬ì…‹
                    enter_time = None
                    capture_triggered = False
            else:
                cv2.putText(frame, "No Face", (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

            # 5. í™”ë©´ ì—…ë°ì´íŠ¸
            frame_window.image(frame, channels="BGR")

            # CPU ì ìœ ìœ¨ ë‚®ì¶”ê¸° (ë¶€ë“œëŸ¬ìš´ ì‹¤í–‰)
            time.sleep(0.03)

    cap.release()